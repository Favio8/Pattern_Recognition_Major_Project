# 聚类算法大作业指南

## 任务概述

基于百度飞桨实现K-means和FCM算法，并在多个数据集上验证。

## 作业要求

1. 查阅无监督聚类的评价标准，选择其中一个标准作为验证指标
2. 在Sonar和MNIST数据上分别训练K-means和FCM聚类算法  
3. 任选三张图像用训练好的聚类算法进行验证

## 文件说明

- `clustering_assignment.ipynb` - 完整的Jupyter Notebook实现
- `README.md` - 本文件，项目说明
- `requirements.txt` - Python依赖包列表

## 快速开始

### 方式1：本地运行

```bash
# 安装依赖
pip install -r requirements.txt

# 启动Jupyter Notebook
jupyter notebook clustering_assignment.ipynb
```

### 方式2：百度AI Studio运行

1. 访问 https://aistudio.baidu.com/project/edit/9609374
2. 注册/登录账号
3. 点击"创建项目" → "Notebook"  
4. 上传 `clustering_assignment.ipynb` 文件
5. 运行所有单元格
6. 点击"分享"获取分享链接

## 算法实现

### K-means算法

- 硬聚类：每个样本只属于一个类别
- 迭代优化簇中心
- K-means++初始化提升性能

### FCM算法（模糊C均值）

- 软聚类：样本可以属于多个类别（不同隶属度）
- 模糊系数m=2
- 更好处理重叠簇

## 评价指标

主要指标：**轮廓系数（Silhouette Coefficient）**

- 范围：[-1, 1]，越接近1越好
- 综合考虑簇内紧密度和簇间分离度

辅助指标：

- Davies-Bouldin指数（越小越好）
- Calinski-Harabasz指数（越大越好）

## 数据集

### 训练数据集

1. **Sonar数据集** - 声纳信号分类（208样本，60特征，2类）
2. **MNIST数据集** - 手写数字识别（使用5000样本子集，784特征，10类）

### 测试图像

从MNIST测试集中选择3张图像，使用训练好的聚类模型进行预测验证

## 实验结果

### 训练阶段

在Sonar和MNIST数据集上训练K-means和FCM算法，包括：

- 定量评价（三种评价指标：轮廓系数、DB指数、CH指数）
- 可视化结果（PCA降维后的2D投影）
- 聚类样本展示

### 验证阶段

使用训练好的模型对3张MNIST测试图像进行预测：

- 展示预测的簇标签
- 对比K-means和FCM的预测结果
- 分析聚类模型的泛化能力

## 关键发现

1. **K-means算法**：
   
   - 优势：计算效率高，结果清晰明确（硬分类）
   - 劣势：对初始值敏感，需预先指定簇数量

2. **FCM算法**：
   
   - 优势：提供隶属度信息（软分类），对噪声更鲁棒
   - 劣势：计算复杂度较高，结果解释相对复杂

3. **数据预处理的重要性**：
   
   - 标准化对聚类效果影响显著
   - PCA降维在保留主要信息的同时降低计算复杂度

4. **测试图像验证**：
   
   - 训练好的模型可以对新图像进行聚类预测
   - 相同数字通常被分配到相同或相近的簇
   - 聚类结果与视觉特征（形状、笔画）相关


